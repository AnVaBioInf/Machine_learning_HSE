# -*- coding: utf-8 -*-
"""Копия блокнота "HW2.ipynb"

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UYejFOaOtgyC5szxnuyVtOG3OaNPPR7e
"""



"""Dataset used: Red wine quality (https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv) \
\
Input variables (based on physicochemical tests):

1 - fixed acidity

2 - volatile acidity

3 - citric acid

4 - residual sugar

5 - chlorides

6 - free sulfur dioxide

7 - total sulfur dioxide

8 - density

9 - pH

10 - sulphates

11 - alcohol

Output variable (based on sensory data):

12 - quality (score between 0 and 10)

## Downloading libraries and data
"""

# importing libraries
import pandas as pd
import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt
import seaborn as sns
from math import sqrt

from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from math import sqrt

# loading the dataset
!wget -O winequality.csv 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'

# reading data into df
df = pd.read_csv("winequality.csv", sep=';')

"""## Exploring the data"""

df.head()

print(df.shape)

print(df.columns)

"""Conclusion: 'total sulfur dioxide' includes 'free sulfur dioxide'. Should one of them be excluded from the dataset?"""

# Checking type of data and % of missing values
df.info()

"""Conclusion: There are no missing values in out data set

### Checking representetion of different classes in the data set
"""

df['quality'].value_counts()

df['quality'].value_counts().plot(kind='bar')
plt.title('Class Frequency Table')
plt.xlabel('Class Type')
plt.ylabel('Counts')

"""Conclusion: clasess are disbalanced

### Checking summary of numerical data
"""

df.describe()

"""Conclusion: Citric acid, recidual sugar, chlorides, dioxide, sulfur dioxide have high std (around +-50% or more)

### Checking type of distribution of the data
"""

df.hist(bins=40, figsize=(12,12))

df.skew()

"""Conclusion: some destributions are scewed

### Checking correletion between the features and noisiness
"""

# Building a correlation matrix
corr_matrix = df.corr()
corr_matrix

plt.figure(figsize=(10,10))
sns.heatmap(corr_matrix,cmap='YlGnBu',annot=True);

"""Conclusion: For this task I decided to predict fixed acidity. Citric acid, dencity and pH are the most promising attributes to predict fixed acidity. All other features have some small influence on prediction, espacially alcohol. 
Moreover, total sulfur dioxide is strongly correlated with free sulfur dioxide.

Above we calculated liniar calculation. Let's build scater plots of the most promicing features to predict fixed acidity to see the noisiness and non-liniar correlation tendencies
"""

# Commented out IPython magic to ensure Python compatibility.
# %config InlineBackend.figure_format = 'png'
sns.pairplot(df[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates']])

"""### Checking the data for outliers"""

fig = plt.figure(figsize=(20,7)) 
ax = fig.gca()
sns.boxplot(data=df)
plt.yscale('log')

"""Conclusion: majority of features have outliers

## Data pre-processing
"""

# removing quality feature from the dataset and highly correlation total sulfur dioxide feature
df = df.drop(['quality','total sulfur dioxide'], axis=1)

# Removing outliers beyond 3 sigma boundaries 
sigma_threshold = 3
low = stats.norm.cdf(-sigma_threshold)
high = stats.norm.cdf(sigma_threshold)
quant_data = df.quantile([low, high])
                         
for name in list(df.drop(labels=['fixed acidity'], axis=1).columns):
    df = df[(df[name] > quant_data.loc[low, name]) & (df[name] < quant_data.loc[high, name])]
print(df.shape)

from sklearn.model_selection import train_test_split

# Splitting data to train and test correspodingly. 80% data-train, 20%-test
X = df.drop(labels=['fixed acidity'], axis=1)
Y = df['fixed acidity']
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state = 42)

# I will perform Z-score and MinMax normalization to choose the most suitable for models
# Standartisation (mean=0, sd=1)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_X_train_arrey = scaler.fit_transform(X_train)
scaled_X_test_arrey = scaler.transform(X_test)

scaled_X_train = pd.DataFrame(scaled_X_train_arrey, index=X_train.index, columns=X_train.columns)
scaled_X_test = pd.DataFrame(scaled_X_test_arrey, index=X_test.index, columns=X_test.columns)

scaled_X_train.hist(bins=40,figsize=(12,12))

# After running the code Z-score normalisation showed better results for models where PCA application is needed 
# Reducing diamentions with PCA
from sklearn.decomposition import PCA

pca = PCA(0.95)  
pca_X_train = pd.DataFrame(pca.fit_transform(scaled_X_train))
pca_X_test = pd.DataFrame(pca.transform(scaled_X_test))

plt.bar(range(pca.n_components_), pca.explained_variance_)
plt.xlabel('PCA feature')
plt.ylabel('variance')
plt.show()

# For NN, Boosting and RF I'll Normalize the data
# Normalisation
from sklearn.preprocessing import MinMaxScaler

norm = MinMaxScaler()
norm_X_train_arrey = norm.fit_transform(X_train)
norm_X_test_arrey = norm.fit_transform(X_test)

norm_X_train = pd.DataFrame(norm_X_train_arrey, index=X_train.index, columns=X_train.columns)
norm_X_test = pd.DataFrame(norm_X_test_arrey, index=X_test.index, columns=X_test.columns)

norm_X_train.hist(bins=40,figsize=(12,12))

"""## Building regression models

### Liniar Regression
"""

from sklearn.linear_model import LinearRegression

linear_rm = LinearRegression()
linear_rm.fit(pca_X_train, Y_train)
linear_rm_predict_Y =linear_rm.predict(pca_X_test)

linear_rm_r2 = r2_score(Y_test, linear_rm_predict_Y)
linear_rm_rmse = sqrt(mean_squared_error(Y_test, linear_rm_predict_Y))
print("R^2: ", linear_rm_r2, "  RMSE: ", linear_rm_rmse) # найти табличку R2-задача регрессии

linear_rm_combined_df = pd.DataFrame({'observed_data' : Y_test, 'predicted_data' : linear_rm_predict_Y})
linear_rm_combined_df

plt.figure(figsize=(5,5))
plt.xlabel('observed')
plt.ylabel('predicted')
plt.title("Observed vs predicted")
plt.scatter(linear_rm_combined_df['observed_data'], linear_rm_combined_df['predicted_data'])

"""### Ridge Regression"""

from sklearn.linear_model import Ridge

alphas = list(range(0,5))
cv = ShuffleSplit(n_splits=5, random_state=0)

ridge_grid_search = GridSearchCV(estimator=Ridge(), param_grid=dict(alpha=alphas), cv=cv)
ridge_grid_search.fit(pca_X_train, Y_train)
ridge_rm_Y_predict =ridge_grid_search.predict(pca_X_test)

print("Best params:", ridge_grid_search.best_params_)
print("Best cross validaton score", ridge_grid_search.best_score_)

ridge_grid_search_r2 = r2_score(Y_test, ridge_rm_Y_predict)
ridge_grid_search_rmse = sqrt(mean_squared_error(Y_test, ridge_rm_Y_predict))
print("R^2: ", ridge_grid_search_r2, "  RMSE: ", ridge_grid_search_rmse)

ridge_combined_df = pd.DataFrame({'observed_data' : Y_test, 'predicted_data' : ridge_rm_Y_predict})
ridge_combined_df

plt.figure(figsize=(5,5))
plt.xlabel('observed')
plt.ylabel('predicted')
plt.title("Observed vs predicted")
plt.scatter(ridge_combined_df['observed_data'], ridge_combined_df['predicted_data'])

"""### Elastic Net"""

from sklearn.linear_model import ElasticNet

# define grid
en_param_grid = {'alpha' : [0.001, 0.01, 0.02],
        'l1_ratio' : [0.01, 0, 0.1],
        'tol' : [0.00001, 0.0001]}

cv = ShuffleSplit(n_splits=5, random_state=0)

# define search
en_grid_search = GridSearchCV(estimator=ElasticNet(), param_grid=en_param_grid, scoring='r2', cv=cv) 
en_grid_search.fit(pca_X_train, Y_train)
en_Y_predict = en_grid_search.predict(pca_X_test)

print("Best params:", en_grid_search.best_params_)
print("Best cross validaton score", en_grid_search.best_score_)

en_search_r2 = r2_score(Y_test, en_Y_predict)
en_search_rmse = sqrt(mean_squared_error(Y_test, en_Y_predict))
print("R^2: ", en_search_r2, "  RMSE: ", en_search_rmse) # найти табличку R2-задача регрессии

en_combined_df = pd.DataFrame({'observed_data' : Y_test, 'predicted_data' : en_Y_predict})
en_combined_df

plt.figure(figsize=(5,5))
plt.xlabel('observed')
plt.ylabel('predicted')
plt.title("Observed vs predicted")
plt.scatter(en_combined_df['observed_data'], en_combined_df['predicted_data'])

"""### Lasso"""

from sklearn.linear_model import Lasso

alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]

cv = ShuffleSplit(n_splits=5, random_state=0)

lasso_grid_search = GridSearchCV(estimator=Lasso(), cv=cv, param_grid=dict(alpha=alphas))
lasso_grid_search.fit(pca_X_train, Y_train)
lasso_predict_Y = lasso_grid_search.best_estimator_.predict(pca_X_test)

print("Best params:", lasso_grid_search.best_params_)
print("Best cross validaton score", lasso_grid_search.best_score_)

lasso_search_r2 = r2_score(Y_test, lasso_predict_Y)
lasso_search_rmse = sqrt(mean_squared_error(Y_test, lasso_predict_Y))
print("R^2: ", lasso_search_r2, "  RMSE: ", lasso_search_rmse) # найти табличку R2-задача регрессии

lasso_combined_df = pd.DataFrame({'observed_data' : Y_test, 'predicted_data' : lasso_predict_Y})
lasso_combined_df

plt.figure(figsize=(5,5))
plt.xlabel('observed')
plt.ylabel('predicted')
plt.title("Observed vs predicted")
plt.scatter(lasso_combined_df['observed_data'], lasso_combined_df['predicted_data'])

"""### SVM (Support Vector Machines)"""

from sklearn.svm import SVR

# kernels - ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ 
# defining parameter range 
svm_param_grid = {'C': list(range(115,130)),  
              'gamma': [0.0001, 0.001, 0.01], 
              'kernel': ['rbf']}  # I checked other types of kernels as well, 'rbf' proved to be the best, it takes considerebly more time to recalculate model with multiple kernels, if I want to tune other parameters, so I lest only one, which works the best

cv = ShuffleSplit(n_splits=5, random_state=0)

svm_grid_search = GridSearchCV(SVR(), svm_param_grid, cv=cv, n_jobs=-1)  
svm_grid_search.fit(pca_X_train, Y_train)
svm_Y_predicted = svm_grid_search.best_estimator_.predict(pca_X_test)

#The best parameters of the model
print("Best params:", svm_grid_search.best_params_)
print("Best cross validaton score", svm_grid_search.best_score_)

svm_r2 = r2_score(Y_test,svm_Y_predicted)
svm_rmse = sqrt(mean_squared_error(Y_test, svm_Y_predicted))
print("R^2: ", svm_r2, "  RMSE: ", svm_rmse)

cvm_combined_df = pd.DataFrame({'observed_data' : Y_test, 'predicted_data' : svm_Y_predicted})
cvm_combined_df

plt.figure(figsize=(5,5))
plt.xlabel('observed')
plt.ylabel('predicted')
plt.title("Observed vs predicted")
plt.scatter(cvm_combined_df['observed_data'], cvm_combined_df['predicted_data'])

"""### Random Forest"""

from sklearn.ensemble import RandomForestRegressor

RF_param_grid = {'max_depth': list(range(15,30)),
                  'min_samples_leaf': [1,2],
                  'min_samples_split': [1,2],
                  'n_estimators': [500]}

cv = ShuffleSplit(n_splits=5, random_state=0)

RF_grid_search = GridSearchCV(RandomForestRegressor(random_state=42, n_jobs=-1), 
                                  RF_param_grid, 
                                  verbose=True, n_jobs=-1, cv=cv,
                                  scoring='r2')

RF_grid_search.fit(norm_X_train, Y_train)
RF_Y_predicted = RF_grid_search.best_estimator_.predict(norm_X_test)

#The best parameters of the model
print("Best params:", RF_grid_search.best_params_)
print("Best cross validaton score", RF_grid_search.best_score_)

# feature importances
# feature importances
pd.DataFrame({'Feature' : list(X_train.columns), 'Importance' : RF_grid_search.best_estimator_.feature_importances_})

RF_r2 = r2_score(Y_test, RF_Y_predicted)
RF_rmse = sqrt(mean_squared_error(Y_test, RF_Y_predicted))
print("R^2: ", RF_r2, "  RMSE: ", RF_rmse)

RF_combined_df = pd.DataFrame({'observed_data' : Y_test, 'predicted_data' : RF_Y_predicted})
RF_combined_df

plt.figure(figsize=(5,5))
plt.xlabel('observed')
plt.ylabel('predicted')
plt.title("Observed vs predicted")
plt.scatter(RF_combined_df['observed_data'], RF_combined_df['predicted_data'])

"""### Gradient Boosting"""

from sklearn.ensemble import GradientBoostingRegressor

GB_grid_search={'n_estimators':[500],
                'learning_rate':[0.01,.1],
                'max_depth':[3,4,5,6],
                'subsample':[.5,.75,1],
                'random_state':[1]}
cv = ShuffleSplit(n_splits=5, random_state=0)

GB_grid_search=GridSearchCV(estimator=GradientBoostingRegressor(),param_grid=GB_grid_search,scoring='neg_mean_squared_error',n_jobs=1,cv=cv)

GB_grid_search.fit(norm_X_train, Y_train)
GB_Y_predicted = GB_grid_search.best_estimator_.predict(norm_X_test)

#The best parameters of the model
print("Best params:", GB_grid_search.best_params_)
print("Best cross validaton score", GB_grid_search.best_score_)

# feature importances
pd.DataFrame({'Feature' : list(X_train.columns), 'Importance' : GB_grid_search.best_estimator_.feature_importances_})

GB_r2 = r2_score(Y_test, GB_Y_predicted)
GB_rmse = sqrt(mean_squared_error(Y_test, GB_Y_predicted))
print("R^2: ", GB_r2, "  RMSE: ", GB_rmse)

GB_combined_df = pd.DataFrame({'observed_data' : Y_test, 'predicted_data' : RF_Y_predicted})
GB_combined_df

plt.figure(figsize=(5,5))
plt.xlabel('observed')
plt.ylabel('predicted')
plt.title("Observed vs predicted")
plt.scatter(GB_combined_df['observed_data'], GB_combined_df['predicted_data'])

"""### Neural Network"""

from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor

def create_model(learn_rate=0.01):
# create model
    model = Sequential()
    model.add(Dense(18, input_dim=9, kernel_initializer='normal', activation='relu'))
    model.add(Dense(36, input_dim=18, kernel_initializer='normal', activation='relu'))
    model.add(Dense(18, input_dim=36, kernel_initializer='normal', activation='relu'))
    model.add(Dense(9, input_dim=18, kernel_initializer='normal', activation='relu'))
    model.add(Dense(1, kernel_initializer='normal'))
    
    # Compile model
    model.compile(loss='mse', optimizer='adam', metrics=['mean_squared_error','mae', 'mape'])
    return model

# create model
model = KerasRegressor(build_fn=create_model)

#define the grid search parameters
param_grid = {'batch_size' : [50, 150, 300],
              'epochs' : [50, 70, 100],
              'learn_rate' : [0.001, 0.01, 0.1]
              }
grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)
grid.fit(norm_X_train, Y_train)
NN_Y_predict = grid.predict(norm_X_test)

print("Best params:", grid.best_params_)
print("Best cross validaton score", grid.best_score_)

NN_r2 = r2_score(Y_test, NN_Y_predict)
NN_rmse = sqrt(mean_squared_error(Y_test, NN_Y_predict))
print("R^2: ", NN_r2, "  RMSE: ", NN_rmse) # найти табличку R2-задача регрессии

NN_combined_df = pd.DataFrame({'observed_data' : Y_test, 'predicted_data' : NN_Y_predict})
NN_combined_df

plt.figure(figsize=(5,5))
plt.xlabel('observed')
plt.ylabel('predicted')
plt.title("Observed vs predicted")
plt.scatter(NN_combined_df['observed_data'], NN_combined_df['predicted_data'])

"""## Summary  Table"""

pd.DataFrame({'Model' : [ 'Liniar Regression', 'Ridge Regression','Elastic Net','Lasso','CVM','Random Forest','Gradient Boosting','Neural Network'],
              'R^2' : [linear_rm_r2,ridge_grid_search_r2, en_search_r2,lasso_search_r2,svm_r2,RF_r2,GB_r2,NN_r2],
              'RMSE' : [linear_rm_rmse, ridge_grid_search_rmse, en_search_rmse,lasso_search_rmse, svm_rmse, RF_rmse,GB_rmse,NN_rmse]})